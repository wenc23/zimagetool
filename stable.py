import torch
from diffusers import ZImagePipeline
from pathlib import Path
import time
import os
import datetime

def get_user_input(prompt_text, default_value=None):
    """è·å–ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒé»˜è®¤å€¼"""
    if default_value:
        user_input = input(f"{prompt_text} (é»˜è®¤: {default_value}): ").strip()
        return user_input if user_input else default_value
    else:
        return input(f"{prompt_text}: ").strip()

def get_integer_input(prompt_text, default_value=None, min_value=None, max_value=None):
    """è·å–æ•´æ•°è¾“å…¥ï¼Œæ”¯æŒèŒƒå›´éªŒè¯"""
    while True:
        try:
            if default_value:
                input_str = input(f"{prompt_text} (é»˜è®¤: {default_value}): ").strip()
                value = int(input_str) if input_str else default_value
            else:
                value = int(input(f"{prompt_text}: ").strip())
            
            if min_value is not None and value < min_value:
                print(f"âŒ å€¼ä¸èƒ½å°äº {min_value}ï¼Œè¯·é‡æ–°è¾“å…¥")
                continue
            if max_value is not None and value > max_value:
                print(f"âŒ å€¼ä¸èƒ½å¤§äº {max_value}ï¼Œè¯·é‡æ–°è¾“å…¥")
                continue
                
            return value
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°")

def select_optimization_mode():
    """è®©ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–æ¨¡å¼"""
    print("\n" + "="*50)
    print("ğŸ”§ è¯·é€‰æ‹©æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼")
    print("="*50)
    print("1. åŸºç¡€ä¼˜åŒ– - å¹³è¡¡æ€§èƒ½å’Œæ˜¾å­˜ä½¿ç”¨")
    print("2. ä½æ˜¾å­˜ä¼˜åŒ– - æœ€å°åŒ–æ˜¾å­˜å ç”¨ï¼Œé€‚åˆä½æ˜¾å­˜è®¾å¤‡")
    
    while True:
        choice = get_integer_input("è¯·é€‰æ‹©ä¼˜åŒ–æ¨¡å¼", 1, 1, 2)
        
        if choice == 1:
            print("âœ… å·²é€‰æ‹©: åŸºç¡€ä¼˜åŒ–æ¨¡å¼")
            return "basic"
        elif choice == 2:
            print("âœ… å·²é€‰æ‹©: ä½æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼")
            return "low_vram"

def apply_low_vram_optimizations(pipe):
    """åº”ç”¨æœ€ä½æ˜¾å­˜ä¼˜åŒ–æ–¹æ³•"""
    print("ğŸ”§ å¯ç”¨ä½æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼...")
    
    try:
        # å…ˆé‡ç½®è®¾å¤‡æ˜ å°„ï¼Œä»¥ä¾¿å¯ç”¨CPUå¸è½½
        if hasattr(pipe, 'reset_device_map'):
            print("ğŸ”„ é‡ç½®è®¾å¤‡æ˜ å°„...")
            pipe.reset_device_map()
        
        # å¯ç”¨æ‰€æœ‰å¯ç”¨çš„å†…å­˜ä¼˜åŒ–æŠ€æœ¯
        pipe.enable_attention_slicing("max")  # æœ€å¤§åˆ‡ç‰‡
        pipe.enable_sequential_cpu_offload()  # é¡ºåºCPUå¸è½½
        
        print("âœ… ä½æ˜¾å­˜ä¼˜åŒ–å·²å¯ç”¨")
    except Exception as e:
        print(f"âš ï¸ å¯ç”¨ä½æ˜¾å­˜ä¼˜åŒ–æ—¶å‡ºé”™: {e}")
        print("ğŸ’¡ å°è¯•ä½¿ç”¨åŸºæœ¬ä¼˜åŒ–...")
        # å¦‚æœå‡ºé”™ï¼Œè‡³å°‘å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡
        pipe.enable_attention_slicing("max")
        print("âœ… å·²å¯ç”¨åŸºæœ¬ä¼˜åŒ–")

def is_high_resolution(width, height):
    """æ£€æŸ¥æ˜¯å¦ä¸ºé«˜åˆ†è¾¨ç‡ï¼ˆå¤§äº2Kï¼‰"""
    # 2Kåˆ†è¾¨ç‡é€šå¸¸æŒ‡2048Ã—1080æˆ–æ›´é«˜
    # è¿™é‡Œæˆ‘ä»¬æ£€æŸ¥ä»»ä¸€è¾¹é•¿å¤§äº2048æˆ–æ€»åƒç´ æ•°å¤§äº2K
    return width > 2048 or height > 2048 or (width * height > 2048 * 1080)

def save_to_gallery(image, filename, prompt, width, height, steps, gen_time, optimization_mode):
    """å°†å›¾ç‰‡ä¿å­˜åˆ°galleryæ–‡ä»¶å¤¹ä¸­çš„å­æ–‡ä»¶å¤¹"""
    # ç¡®ä¿galleryæ–‡ä»¶å¤¹å­˜åœ¨
    gallery_dir = Path("gallery")
    gallery_dir.mkdir(exist_ok=True)
    
    # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºå­æ–‡ä»¶å¤¹å
    base_name = Path(filename).stem
    extension = Path(filename).suffix
    
    # åˆ›å»ºä»¥æ–‡ä»¶åå‘½åçš„å­æ–‡ä»¶å¤¹
    image_folder = gallery_dir / base_name
    
    # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
    if image_folder.exists():
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        image_folder = gallery_dir / f"{base_name}_{timestamp}"
    
    image_folder.mkdir(exist_ok=True)
    
    # ä¿å­˜å›¾ç‰‡åˆ°å­æ–‡ä»¶å¤¹
    image_path = image_folder / f"{base_name}{extension}"
    image.save(image_path)
    
    # åˆ›å»ºå‚æ•°ä¿¡æ¯æ–‡ä»¶
    info_file = image_folder / f"{base_name}_info.txt"
    with open(info_file, 'w', encoding='utf-8') as f:
        f.write(f"å›¾ç‰‡åç§°: {base_name}{extension}\n")
        f.write(f"æç¤ºè¯: {prompt}\n")
        f.write(f"å›¾ç‰‡å°ºå¯¸: {width}x{height}\n")
        f.write(f"æ¨ç†æ­¥æ•°: {steps}\n")
        f.write(f"ä¼˜åŒ–æ¨¡å¼: {optimization_mode}\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {gen_time:.2f}ç§’\n")
        f.write(f"åˆ›å»ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    return image_folder

def interactive_generate(pipe, optimization_mode):
    """äº¤äº’å¼ç”Ÿæˆå›¾ç‰‡"""
    print("\n" + "="*50)
    print("ğŸ¨ äº¤äº’å¼å›¾ç‰‡ç”Ÿæˆ")
    print("="*50)
    
    # æ ‡è®°æ˜¯å¦å·²åº”ç”¨ä½æ˜¾å­˜ä¼˜åŒ–
    low_vram_applied = False
    
    while True:
        print("\nè¯·è¾“å…¥å›¾ç‰‡ç”Ÿæˆå‚æ•°:")
        
        # è·å–ç”¨æˆ·è¾“å…¥
        prompt = get_user_input("æç¤ºè¯")
        if not prompt:
            print("âŒ æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            continue
            
        filename = get_user_input("æ–‡ä»¶å", "generated_image.png")
        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            filename += '.png'
            
        width = get_integer_input("å›¾ç‰‡å®½åº¦", 1024, 256, 4096)
        height = get_integer_input("å›¾ç‰‡é«˜åº¦", 1024, 256, 4096)
        steps = get_integer_input("æ¨ç†æ­¥æ•°", 15, 1, 50)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜åˆ†è¾¨ç‡ï¼Œå¦‚æœæ˜¯ä¸”æœªåº”ç”¨ä½æ˜¾å­˜ä¼˜åŒ–ï¼Œåˆ™åº”ç”¨
        if is_high_resolution(width, height) and not low_vram_applied and optimization_mode != "low_vram":
            print(f"\nâš ï¸ æ£€æµ‹åˆ°é«˜åˆ†è¾¨ç‡å›¾ç‰‡ ({width}x{height})ï¼Œå¯ç”¨ä½æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼...")
            apply_low_vram_optimizations(pipe)
            low_vram_applied = True
        
        # ç”Ÿæˆå›¾ç‰‡
        print(f"\nğŸ”„ å¼€å§‹ç”Ÿæˆå›¾ç‰‡: {prompt}")
        start_time = time.time()
        
        try:
            image = pipe(
                prompt=prompt,
                height=height,
                width=width,
                num_inference_steps=steps,
                guidance_scale=0.0,  # å›ºå®šå¼•å¯¼å¼ºåº¦ä¸º0.0
            ).images[0]
            
            gen_time = time.time() - start_time
            
            # ä¿å­˜å›¾ç‰‡åˆ°galleryæ–‡ä»¶å¤¹ä¸­çš„å­æ–‡ä»¶å¤¹
            gallery_folder = save_to_gallery(image, filename, prompt, width, height, steps, gen_time, optimization_mode)
            print(f"âœ… å›¾ç‰‡å·²ä¿å­˜åˆ°gallery: {gallery_folder}")
            
            print(f"â±ï¸ ç”Ÿæˆæ—¶é—´: {gen_time:.2f}ç§’")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            # å¦‚æœæ˜¯æ˜¾å­˜ä¸è¶³é”™è¯¯ï¼Œå°è¯•åº”ç”¨ä½æ˜¾å­˜ä¼˜åŒ–
            if "out of memory" in str(e).lower() and not low_vram_applied:
                print("ğŸ’¡ æ£€æµ‹åˆ°æ˜¾å­˜ä¸è¶³ï¼Œå°è¯•å¯ç”¨ä½æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼...")
                apply_low_vram_optimizations(pipe)
                low_vram_applied = True
                print("è¯·é‡è¯•ç”Ÿæˆ...")
                continue
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        continue_choice = input("\næ˜¯å¦ç»§ç»­ç”Ÿæˆä¸‹ä¸€å¼ å›¾ç‰‡? (y/n): ").strip().lower()
        if continue_choice != 'y':
            break
    
    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§!")

def main():
    # è®©ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–æ¨¡å¼
    optimization_mode = select_optimization_mode()
    
    local_model_path = Path("models/Z-Image-Turbo")
    
    if not local_model_path.exists():
        print(f"âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {local_model_path}")
        return
    
    print(f"ğŸ“ ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹: {local_model_path}")
    
    start_time = time.time()
    try:
        # æ ¹æ®ä¼˜åŒ–æ¨¡å¼é€‰æ‹©åŠ è½½å‚æ•°
        if optimization_mode == "low_vram":
            # ä½æ˜¾å­˜ä¼˜åŒ–æ¨¡å¼ä½¿ç”¨ä¸åŒçš„åŠ è½½å‚æ•°
            pipe = ZImagePipeline.from_pretrained(
                str(local_model_path),
                torch_dtype=torch.bfloat16,
                low_cpu_mem_usage=True,
                local_files_only=True,
                offload_folder="offload",
            )
            
            # åº”ç”¨ä½æ˜¾å­˜ä¼˜åŒ–
            apply_low_vram_optimizations(pipe)
        else:
            # åŸºç¡€ä¼˜åŒ–æ¨¡å¼ä½¿ç”¨å¹³è¡¡æ¨¡å¼åˆ†é…è®¾å¤‡
            pipe = ZImagePipeline.from_pretrained(
                str(local_model_path),
                torch_dtype=torch.bfloat16,
                low_cpu_mem_usage=True,
                local_files_only=True,
                device_map="balanced",  # ä½¿ç”¨å¹³è¡¡æ¨¡å¼åˆ†é…è®¾å¤‡
            )
            
            # å¯ç”¨åŸºæœ¬æ˜¾å­˜ä¼˜åŒ–
            pipe.enable_attention_slicing("max")
        
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ! è€—æ—¶: {load_time:.2f}ç§’")
        
        # è¿›å…¥äº¤äº’å¼ç”Ÿæˆæ¨¡å¼
        interactive_generate(pipe, optimization_mode)
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return
    
    # ä¸æ¸…ç†æ˜¾å­˜ï¼Œä¿æŒæ¨¡å‹åŠ è½½çŠ¶æ€
    print("\nğŸ“ æ¨¡å‹ä¿æŒåŠ è½½çŠ¶æ€")

if __name__ == "__main__":
    main()